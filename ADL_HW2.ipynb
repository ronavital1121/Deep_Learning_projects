{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ADL HW2 - PCA and Autoencoders\n",
        "In this assignment you will implement two dimensionality reduction schemes\n",
        "we saw in class:\n",
        "1. Principal Component Analysis (PCA)\n",
        "2. Autoencoder\n",
        "\n",
        "You will also implement an image denoising model to enhance the performance of a simple MLP classifier.\n",
        "\n",
        "The data used in the following exercises is a subset of the MNIST dataset.\n",
        "Randomly sample 10,000 images from MNIST train set (you may set a random.seed).\n",
        "\n",
        "# Submission Date: 05.01.2025\n",
        "Submit the already-run notebook.\n"
      ],
      "metadata": {
        "id": "lj7a3Uymf0tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "GUI6oBKUksM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX1. PCA dimensionality reduction (10pts)\n",
        "\n",
        "1. Implement the PCA procedure in the function ```perform_PCA()```.\n",
        "\n",
        "Useful functions:\n",
        "```\n",
        "sklearn.preprocessing.StandardScaler\n",
        "scipy.linalg.eigh\n",
        "numpy.matmul\n",
        "```\n",
        "The input should be in vector form (i.e., flatten the input images beforehand).\n",
        "\n",
        "2. Project the data to 2D, i.e, $\\mathbb{R}^{784}â†¦ \\mathbb{R}^2$.\n",
        "3. Scatter plot the data using the 2D projection and class labels. You'll need to implement ```plot_projected_data()```\n"
      ],
      "metadata": {
        "id": "r1d6cEcvgBZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_PCA(X, n_components):\n",
        "  \"\"\"\n",
        "  Implement the PCA algorithm.\n",
        "  Input: X [numpy array] - shape: (N,784)\n",
        "  Output: Projected data using n_components\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "def plot_projected_data(X, y):\n",
        "  pass"
      ],
      "metadata": {
        "id": "BDOUHt7Xf-Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For EX5, Please use the (0.5, 0.5) normalization value, as\n",
        "# they were used for training the MLP\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST train and test datasets\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Sample 10K images\n",
        "train_indices = np.random.choice(len(trainset), 10000, replace=False)\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "\n",
        "trainloader = DataLoader(train_subset , batch_size=256, shuffle=True, num_workers=4)\n",
        "testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "ktYX3dGkKJG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code goes here ###"
      ],
      "metadata": {
        "id": "kWtj9xT5jFzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX2 Autoencoder (AE) (15pts)\n",
        "1. Implement a fully-connected Autoencoder. The encoder and decoder should have 2 layers each. Use ReLU activation function.\n",
        "2. The so-called 'code' should be two-dimensional. In other words, the output of the encoder should be 2.\n",
        "3. Plot the training loss.\n",
        "\n",
        "4. Project the data using your AE. Plot the data using ```plot_projected_data()```"
      ],
      "metadata": {
        "id": "j5wxEcWyjSDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MLP_AE, self).__init__()\n",
        "      self.encoder = # TODO\n",
        "      self.decoder = # TODO\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.encoder(x)\n",
        "      x = self.decoder(x)\n",
        "      return x\n",
        "\n"
      ],
      "metadata": {
        "id": "6WNrTlDQjpQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code goes here ###"
      ],
      "metadata": {
        "id": "MN8Lc75VKPms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX3 Linear Autoencoder (15pts)\n",
        "1. Follow the steps of EX2, but remove the nonlinear activation functions.\n",
        "\n",
        "4. Project the data using your AE. Plot the data using ```plot_projected_data()```"
      ],
      "metadata": {
        "id": "5tIPQavolCBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MLP_AE, self).__init__()\n",
        "      self.encoder = # TODO\n",
        "      self.decoder = # TODO\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.encoder(x)\n",
        "      x = self.decoder(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "ZXcp4BUxk0Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code goes here ###"
      ],
      "metadata": {
        "id": "33-kYqXBKQEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX 4 - Discussion (10pts)\n",
        "1. Write a new plotting function and plot the results side-by-side using subplots.\n",
        "2. Given the three figures and what we've learned about PCA and AE, answer what are the difference/similarites between the models? How is that indicated in the results?\n"
      ],
      "metadata": {
        "id": "99KVy3m8lTQl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URZU_ISclR1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX 5 - Denoising AE and Classification (50pts.)\n",
        "In this section you will implement and train a denosing AE to clean corrupted MNIST images.\n",
        "You are given a trained MLP model (from DL PS1) with ~94% test set accuracy on the cleaned images. Again, work with only 10k images (a subset of the train set).\n",
        "Your tasks are as follows:\n",
        "0. Load the mlp.pth file to your project (not google drive dir) and initiate the MLP model with the trained weights.\n",
        "1. Compute the test set accuracy for the clean and corrupted datasets.\n",
        "2. Implemented and train autoencoder to remove the noise.\n",
        "3. Visualize the results for 10 images, one for each digit (original image, corrupted image, clean image).\n",
        "4. Compute the test set accuracy on the cleaned/denoised corrupted test set. Due to the randomness of the gaussian noise, run the procedure 5 times and take the average accuracy.\n",
        "\n",
        "You **may not re-train** the classification network or train a new model for classification task.\n",
        "\n",
        "There is **no need** to submit the trained model weights.\n",
        "\n",
        "### Grading for this section:\n",
        "```python\n",
        "50pts = max(cleaned image accuracy + 10, 100)*0.5 #(i.e, accuracy >= 90% will give you a full grade).\n",
        "```\n",
        "\n",
        "You will also be evaluated on the quality of your code and apporach."
      ],
      "metadata": {
        "id": "lYYa1CoXR395"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load trained model"
      ],
      "metadata": {
        "id": "vx1qxVRczgFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP classifier from DL PS1 - DO NOT CHANGE\n",
        "mlp_clf = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mlp_clf.load_state_dict(torch.load('mlp.pth', map_location=torch.device(device)))\n"
      ],
      "metadata": {
        "id": "CM3ly_hsSOc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data and functions"
      ],
      "metadata": {
        "id": "ad33HrCjHKvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Noise function - DO NOT CHANGE\n",
        "def add_gaussian_noise(images, mean=0.0, std=2):\n",
        "    noise = torch.randn(images.size()) * std + mean\n",
        "    noisy_images = images + noise\n",
        "    return noisy_images\n",
        "\n",
        "\n",
        "# Accuracy - DO NOT CHANGE\n",
        "def compute_accuracy(model, testloader, denoise_model=None, add_noise=False):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            # False for clean images, True for corrupted/noisy\n",
        "            if add_noise:\n",
        "              images = add_gaussian_noise(images)\n",
        "            # Denoise the image before the classifier\n",
        "            if denoise_model is not None:\n",
        "              images = denoise_model(images)\n",
        "            # reshape to vector form for the MLP\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "yNBtA4a1h19b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print test accuracy for clean and corrupted images\n"
      ],
      "metadata": {
        "id": "Dechg3Z_lZAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code goes here ###"
      ],
      "metadata": {
        "id": "KwvEq5VjpMKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}